name: Build QML Branch
on:
  workflow_call:
    inputs:
      branch:
        description: The QML branch to checkout and build demos for
        required: true
        type: string
      num_workers:
        description: The number of workers to use for building the QML demos
        required: true
        type: string
      sphinx_examples_to_build:
        description: |
          Instead of building all Sphinx Examples, only build the ones passed.
          To build multiple demos, pass the filenames separated by space.
          Leave as blank to build all demos (default behavior)
        required: false
        type: string
        default: ''
      enable_sphinx_cache:
        description: Use actions/cache for sphinx and sphinx-gallery
        required: false
        type: boolean
        default: false
      refresh_sphinx_cache:
        description: Build QML Demos without using cache and create new caches after the build
        required: false
        type: boolean
        default: false
      sphinx_build_output_format:
        description: Indicate what the output type of Sphinx-Build should be (format will be HTML, the HTML can be in .html file or in JSON format)
        required: false
        type: string
        default: html
      enable_python_cache:
        description: Use actions/cache for python packages being installed
        required: false
        type: boolean
        default: false
      enable_qml_execution_times_cache:
        description: Indicate if the execution_times file should be cache or fetched fresh
        required: false
        type: boolean
        default: false
      skip_execution_times_aggregation:
        description: Skip aggregating all the execution times from all workers into one file
        required: false
        type: boolean
        default: false
      skip_sphinx_build_file_aggregation:
        description: Skip aggregating the html files built from all workers into one zip file
        required: false
        type: boolean
        default: false

jobs:
  validate-inputs:
    runs-on: ubuntu-22.04
    steps:
      - name: Validate inputs.sphinx_build_output_format
        run: |
          valid_choices='html json'
          [[ " $valid_choices " =~ " ${{ inputs.sphinx_build_output_format }} " ]] && exit 0 || exit 1

  compute-build-strategy-matrix:
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.branch }}
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install QML Pipeline Utils
        run: |
          cd .github/workflows/qml_pipeline_utils
          pip install .

      - name: Execution Times Cache
        id: execution_times_cache
        if: inputs.enable_qml_execution_times_cache == true && inputs.sphinx_examples_to_build == ''
        uses: actions/cache@v3
        with:
          path: execution_times.json
          key: execution_times-${{ inputs.branch }}

      - name: Fetch Execution Times Target Branch
        id: build_environment_branch
        run: |
          current_build_branch='${{ inputs.branch }}'
          pull_request_target_branch='${{ github.event.pull_request.base.ref }}'
          if [[ "$current_build_branch" == "dev" || "$pull_request_target_branch" == "dev" ]]; then
            name="dev"
          else
            name="master"
          fi
          echo $name
          echo "name=$name" >> $GITHUB_OUTPUT

      - name: Fetch Execution Times Target Branch Latest Workflow run ID
        id: workflow_run_id
        if: steps.execution_times_cache.outputs.cache-hit != 'true' && inputs.sphinx_examples_to_build == ''
        uses: actions/github-script@v6
        with:
          result-encoding: string
          script: |
            const destWorkflowBranch = "${{ steps.build_environment_branch.outputs.name }}";

            try {
              const workflowRuns = await github.rest.actions.listWorkflowRuns({
                owner: context.repo.owner,
                repo: context.repo.repo,
                workflow_id: `build-branch-${destWorkflowBranch}.yml`,
                branch: 'master',
                status: 'success',
                exclude_pull_requests: true,
                per_page: 1,
                page: 1
              });
              const runData = workflowRuns.data.workflow_runs;
              return (runData.length) ? runData[0].id : '';
            } catch (e) {
              console.log(`Unable to fetch workflow ID, error: ${e}`);
              return '';
            }

      - name: Download Demo Execution run times
        if: >-
          ${{
             steps.execution_times_cache.outputs.cache-hit != 'true' &&
             steps.workflow_run_id.outputs.result != '' &&
             inputs.sphinx_examples_to_build == ''
           }}
        uses: XanaduAI/cloud-actions/download-github-workflow-artifact@main
        with:
          workflow_run_id: ${{ steps.workflow_run_id.outputs.result }}
          artifact_name_regex: execution_times\.zip
          github_token: ${{ github.token }}

      - name: Unpack Execution run times file
        if: >-
          ${{
             steps.execution_times_cache.outputs.cache-hit != 'true' &&
             steps.workflow_run_id.outputs.result != '' &&
             inputs.sphinx_examples_to_build == ''
           }}
        run: |
          ls
          FILE='execution_times.zip.zip'
          if [ -f "$FILE" ]; then
            echo "$FILE exists."
            unzip execution_times.zip
          fi

      - name: Check Execution Times file exists
        id: check_execution_times_file_existence
        run: |
          [ -f "execution_times.json" ] && result='true' || result='false'
          echo $result
          echo "result=$result" >> $GITHUB_OUTPUT

          if [ "$result" == "true" ]; then
            build_arg='--sphinx-examples-execution-times-file=${{ github.workspace }}/execution_times.json'
          else
            build_arg=''
          fi
          echo "build_arg=$build_arg" >> $GITHUB_OUTPUT

      - name: Remove Demonstrations that do not need to be built
        if: inputs.sphinx_examples_to_build != ''
        env:
          DEMOS_TO_BUILD: ${{ inputs.sphinx_examples_to_build }}
        run: |
          readarray -td ' ' demos_to_retain <<<"$DEMOS_TO_BUILD "; unset 'demos_to_retain[-1]'; declare -p demos_to_retain;
          find demonstrations -maxdepth 1 -type f | grep -vE "$(IFS=\| && echo "${demos_to_retain[*]}")" | xargs -r rm

      - name: Generate Build Matrix
        id: compute-strategy-matrix
        run: |
          WK_LOAD_ARTIFACT_NAME='worker_load'
          WK_LOAD_FILE_NAME='${{ github.workspace }}/worker_load.json'
          touch $WK_LOAD_FILE_NAME

          echo "$(qml_pipeline_utils \
            build-strategy-matrix \
            --num-workers=${{ inputs.num_workers }} \
            --examples-dir='${{ github.workspace }}/demonstrations' \
            ${{ steps.check_execution_times_file_existence.outputs.build_arg }})" >> $WK_LOAD_FILE_NAME

          echo "worker_load_artifact_name=$WK_LOAD_ARTIFACT_NAME" >> $GITHUB_OUTPUT
          echo "worker_load_file_name=$WK_LOAD_FILE_NAME" >> $GITHUB_OUTPUT

          cat "$WK_LOAD_FILE_NAME" | jq

          worker_count=$(jq -r '.workers | length' "$WK_LOAD_FILE_NAME")
          matrix=$(python -c "print(list(range($worker_count)))")
          echo "strategy-matrix=$matrix" >> $GITHUB_OUTPUT

      - name: Upload Workers Load Data as Artifact
        uses: actions/upload-artifact@v3
        with:
          name: ${{ steps.compute-strategy-matrix.outputs.worker_load_artifact_name }}
          path: ${{ steps.compute-strategy-matrix.outputs.worker_load_file_name }}

    outputs:
      build-environment: ${{ steps.build_environment_branch.outputs.name }}
      strategy-matrix: ${{ steps.compute-strategy-matrix.outputs.strategy-matrix }}
      worker-load-file-name: ${{ steps.compute-strategy-matrix.outputs.worker_load_file_name }}
      worker-load-artifact-name: ${{ steps.compute-strategy-matrix.outputs.worker_load_artifact_name }}

  validate-poetry-lock-file:
    runs-on: ubuntu-22.04

    needs:
      - compute-build-strategy-matrix

    steps:
      - uses: actions/checkout@v3
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'master'
        with:
          ref: ${{ inputs.branch }}
          fetch-depth: 1

      - name: Set up Python Version
        id: setup_python
        uses: actions/setup-python@v4
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'master'
        with:
          python-version: 3.9

      - name: Install Poetry
        id: poetry
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'master'
        env:
          POETRY_HOME: /tmp/poetry
        run: |
          curl -sSL https://install.python-poetry.org -o install-poetry.py
          python3 install-poetry.py --version 1.5.1
          echo "bin=${{ env.POETRY_HOME }}/bin/poetry }}" >> $GITHUB_OUTPUT

      - name: Validate Poetry Lockfile
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'master'
        run: ${{ steps.poetry.outputs.bin }} -C build_requirements/${{ needs.compute-build-strategy-matrix.outputs.build-environment }} lock --check

  build-branch:
    runs-on: ubuntu-22.04
    needs:
      - compute-build-strategy-matrix
      - validate-inputs
      - validate-poetry-lock-file
    strategy:
      matrix:
        offset: ${{ fromJson(needs.compute-build-strategy-matrix.outputs.strategy-matrix) }}
    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${{ inputs.branch }}
          fetch-depth: 1

      - name: Set up Python Version
        id: setup_python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Python Environment Cache
        if: inputs.enable_python_cache == true
        uses: actions/cache@v3
        with:
          path: venv
          key: pip-${{ steps.setup_python.outputs.python-version }}-${{ hashFiles('build_requirements/**/pyproject.toml') }}

      - name: Setup Python Environment
        id: venv
        run: |
          if [ ! -d "venv" ]; then python3 -m venv venv; fi
          echo "location=${{ github.workspace }}/venv" >> $GITHUB_OUTPUT
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

      - name: Install QML Pipeline Utils
        run: |
          cd .github/workflows/qml_pipeline_utils
          ${{ steps.venv.outputs.location }}/bin/python3 -m pip install .

      - name: Install Poetry
        id: poetry
        env:
          POETRY_HOME: /tmp/poetry
        run: |
          curl -sSL https://install.python-poetry.org -o install-poetry.py
          python3 install-poetry.py --version 1.5.1
          
          $POETRY_HOME/bin/poetry config virtualenvs.create "false"
          $POETRY_HOME/bin/poetry config virtualenvs.in-project "true"
          
          $POETRY_HOME/bin/poetry --version
          
          echo "bin=${{ env.POETRY_HOME }}/bin/poetry" >> $GITHUB_OUTPUT

      - name: Cache Poetry Lockfile (Dev)
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'dev'
        uses: actions/cache@v3
        with:
          path: build_requirements/dev/poetry.lock
          key: dev-poetry-lock-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            dev-poetry-lock-${{ github.ref_name }}-
            dev-poetry-lock-

      - name: Install Python Dependencies
        run: |
          source ${{ steps.venv.outputs.location }}/bin/activate
          ${{ steps.poetry.outputs.bin }} -C build_requirements/${{ needs.compute-build-strategy-matrix.outputs.build-environment }} install
          
          # Adding this install outside of poetry as the dependencies conflict with existing other packages.
          # TODO: This needs to be revisited.
          ${{ steps.venv.outputs.location }}/bin/python3 -m pip install --no-deps mitiq==0.25.0

      # Since poetry always attempts to pin packages to a certain release (or git sha)
      # This update step pulls the latest pennylane packages from their respective master branches
      - name: Update Dependencies (Dev)
        if: needs.compute-build-strategy-matrix.outputs.build-environment == 'dev'
        run: ${{ steps.poetry.outputs.bin }} -C build_requirements/dev update

      - name: Download Worker Load Data Artifact
        uses: actions/download-artifact@v3
        with:
          name: ${{ needs.compute-build-strategy-matrix.outputs.worker-load-artifact-name }}

      - name: Extract Current Worker Tasks
        id: worker_tasks
        env:
          worker_id: ${{ matrix.offset }}
          worker_load_file_name: ${{ needs.compute-build-strategy-matrix.outputs.worker-load-file-name }}
        run: |
          WK_TASKS_FILE_NAME='worker_tasks.json'
          jq .workers[${{ env.worker_id }}].tasks ${{ env.worker_load_file_name }} > "$WK_TASKS_FILE_NAME"
          
          cat "$WK_TASKS_FILE_NAME" | jq
          
          echo "file_name=$WK_TASKS_FILE_NAME" >> $GITHUB_OUTPUT 

      # Creates a temp yaml file with current environment information:
      # ```
      #  nonce: arbitrary value, we can change this to invalidate all previous caches if needed
      #  num_workers: The total number of workers currently spawned
      #  worker_id: The offset in the strategy matrix for the current worker
      #  python.version: The version of python that was setup using actions/setup-python
      #  python.hash.requirements-txt: The hash of the requirements.txt file
      #  python.hash.requirements_no_deps-txt: The hash of the requirements_no_deps.txt file
      # ```
      # The hash of this file is used as portion of the key in subsequent caching steps.
      # This ensures that if the values in this file change,
      # it will invalidate the previous cache and build fresh.
      - name: Set Matrix offset file
        run: |
          worker_files=$(jq [.[].name] ${{ steps.worker_tasks.outputs.file_name }} | sed 's/^/  /')
          cat >matrix_info.yaml <<EOL
          nonce: a
          
          num_workers: ${{ inputs.num_workers }}
          worker_id: ${{ matrix.offset }}
          
          python:
            version: ${{ steps.setup_python.outputs.python-version }}
            hash:
              requirements-txt: ${{ hashFiles('requirements.txt') }}
              requirements_no_deps-txt: ${{ hashFiles('requirements_no_deps.txt') }}
          
          worker_files: |
          $worker_files
          EOL

          cat matrix_info.yaml

      - name: Generate hash of the matrix file
        id: matrix_file
        if: inputs.enable_sphinx_cache == true
        run: |
          echo "hash=${{ hashFiles('matrix_info.yaml') }}" >> $GITHUB_OUTPUT

      - name: Install OS build dependencies
        run: |
          sudo apt-get install -y pandoc --quiet

      # Removes executable code from tutorials that are not relevant to current node
      # See documentation in github_job_scheduler.py for more details.
      - name: Remove extraneous executable code from demos
        run: |
          ${{ steps.venv.outputs.location }}/bin/qml_pipeline_utils \
          remove-executable-code-from-extraneous-demos \
          --worker-tasks-file-loc="${{ steps.worker_tasks.outputs.file_name }}" \
          --examples-dir="${{ github.workspace }}/demonstrations" \
          --verbose

      - name: Gallery Cache
        if: inputs.enable_sphinx_cache == true
        uses: actions/cache@v3
        with:
          path: demos
          key: gallery-${{ steps.matrix_file.outputs.hash }}-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            gallery-${{ steps.matrix_file.outputs.hash }}-${{ github.ref_name }}-
            gallery-${{ steps.matrix_file.outputs.hash }}-

      - name: Sphinx Cache
        if: inputs.enable_sphinx_cache == true
        uses: actions/cache@v3
        with:
          path: sphinx_cache-${{ steps.matrix_file.outputs.hash }}
          key: sphinx-${{ steps.matrix_file.outputs.hash }}-${{ github.ref_name }}-${{ github.sha }}
          restore-keys: |
            sphinx-${{ steps.matrix_file.outputs.hash }}-${{ github.ref_name }}-
            sphinx-${{ steps.matrix_file.outputs.hash }}-

      - name: Clear Cache
        if: inputs.refresh_sphinx_cache == true
        env:
          sphinx_cache_filename: sphinx_cache-${{ steps.matrix_file.outputs.hash }}
        run: |
          if [ -d demos ]; then rm -rf demos; fi
          if [ -d ${{ env.sphinx_cache_filename }} ]; then rm -rf ${{ env.sphinx_cache_filename }}; fi

      - name: Build Tutorials
        run: |
          make download
          make SPHINXBUILD="${{ steps.venv.outputs.location }}/bin/sphinx-build" SPHINXOPTS="-d sphinx_cache-${{ steps.matrix_file.outputs.hash }}" ${{ inputs.sphinx_build_output_format }}

      - name: Generate Execution Time Map
        run: |
          mkdir /tmp/execution_times

          ${{ steps.venv.outputs.location }}/bin/qml_pipeline_utils \
          parse-execution-times \
          --worker-tasks-file-loc="${{ steps.worker_tasks.outputs.file_name }}" \
          --build-type="${{ inputs.sphinx_build_output_format }}" \
          --examples-dir="${{ github.workspace }}/demonstrations" \
          --build-dir="${{ github.workspace }}/_build/html" > /tmp/execution_times/execution_times.json
          
          cat /tmp/execution_times/execution_times.json | jq

      - name: Upload Execution Times
        uses: actions/upload-artifact@v3
        with:
          name: execution_times_${{ matrix.offset }}.zip
          if-no-files-found: error
          retention-days: 1
          path: /tmp/execution_times

      # These are files that are generated as part of sphinx-build but are not needed and supported on the live website
      # There does not seem to be an option to "not" generate them, therefore this step deletes these files before they
      # are published to the live website.
      - name: Update sitemap.xml
        run: |
          ${{ steps.venv.outputs.location }}/bin/qml_pipeline_utils \
          clean-sitemap \
          --build-dir="${{ github.workspace }}/_build/html" \
          --html-files="demos/sg_execution_times.html" \
          --verbose

      # Removes built html files that are not relevant to current node
      # See documentation in github_job_scheduler.py for more details.
      - name: Clean HTML Files
        if: matrix.offset == 0
        run: |
          ${{ steps.venv.outputs.location }}/bin/qml_pipeline_utils \
          remove-extraneous-built-html-files \
          --worker-tasks-file-loc="${{ steps.worker_tasks.outputs.file_name }}" \
          --build-dir="${{ github.workspace }}/_build/html" \
          --examples-dir="${{ github.workspace }}/demonstrations" \
          --build-type="${{ inputs.sphinx_build_output_format }}" \
          --preserve-non-sphinx-images \
          --verbose

      - name: Clean HTML Files and Images
        if: matrix.offset != 0
        run: |
          ${{ steps.venv.outputs.location }}/bin/qml_pipeline_utils \
          remove-extraneous-built-html-files \
          --worker-tasks-file-loc="${{ steps.worker_tasks.outputs.file_name }}" \
          --build-dir="${{ github.workspace }}/_build/html" \
          --examples-dir="${{ github.workspace }}/demonstrations" \
          --build-type="${{ inputs.sphinx_build_output_format }}" \
          --verbose

      - name: Upload Html
        if: matrix.offset == 0
        uses: actions/upload-artifact@v3
        with:
          name: html-${{ matrix.offset }}.zip
          if-no-files-found: error
          retention-days: 1
          path: _build/html

      # Only upload demos since all other html files are pushed as artifact from offset 0
      # This step excludes static files (files that are the same across all workers) from being included in the
      # built artifact. This is done as a performance boost.
      # The step above this is executed by only one worker which uploads all static content.
      - name: Upload Demo Html
        if: matrix.offset != 0
        uses: actions/upload-artifact@v3
        with:
          name: html-${{ matrix.offset }}.zip
          if-no-files-found: error
          retention-days: 1
          path: |
            _build/html
            !_build/html/*.html
            !_build/html/*.fjson
            !_build/html/*.js
            !_build/html/*.xml
            !_build/html/_static
            !_build/html/glossary

  aggregate_build:
    runs-on: ubuntu-22.04
    if: inputs.skip_execution_times_aggregation == false || inputs.skip_sphinx_build_file_aggregation == false
    needs:
      - build-branch
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v3
        with:
          path: artifacts

      - name: Merge Execution Times
        if: inputs.skip_execution_times_aggregation == false
        run: |
          cd artifacts
          mkdir execution_times_all /tmp/execution_times
          for f in execution_times_*.zip; do
            new_name=execution_times-\($f\).json
            mv $f/execution_times.json execution_times_all/$new_name
            echo execution_times_all/$new_name
            cat execution_times_all/$new_name | jq
          done
          jq -s 'reduce .[] as $item ({}; . * $item)' execution_times_all/* | tee /tmp/execution_times/execution_times.json

          cat /tmp/execution_times/execution_times.json | jq

      - name: Merge Sphinx Build Files
        if: inputs.skip_sphinx_build_file_aggregation == false
        run: |
          cd artifacts
          mkdir -p website/demos
          for f in html-*.zip; do
            rsync -a --progress "$f/" website
          done

      - name: Upload Sphinx Build files
        if: inputs.skip_sphinx_build_file_aggregation == false
        uses: actions/upload-artifact@v3
        with:
          name: ${{ inputs.sphinx_build_output_format }}.zip
          if-no-files-found: error
          path: artifacts/website

      - name: Upload Execution Times
        if: inputs.skip_execution_times_aggregation == false
        uses: actions/upload-artifact@v3
        with:
          name: execution_times.zip
          path: /tmp/execution_times
